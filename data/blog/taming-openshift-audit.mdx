---
title: Taming OpenShift audit with RHACS
date: '2024-10-27'
tags: ['openshift','audit','rhacs','security','compliance','stackrox']
images: ['/static/images/linkedin-banners/taming-openshift-audit.png']
draft: false
summary: 'Event log capture and audit is a core requirement for threat detection and digital forensic investigation. But, it is very expensive to keep audit and event log data indexed and readily searchable. In this article I will look at some alternate approaches to manage OpenShift audit and event data, and how you can create immediate alerts from OpenShift audit events.'
---
As a kid I loved a book called ['Two Minute Mysteries'](https://www.amazon.com.au/Two-Minute-Mysteries-Donald-J-Sobol/dp/0590447874), by Donald J.Sobol. It was a collection of incredibly short stories, just over a page long, where the reader pretended to be Watson to the detective "Dr Haledjian". He was able to rapidly discern whether someone was lying from a minute detail, and the reader was left to wonder how. I can vividly remember the cover.

<Zoom>
![mysteries](/static/images/ocp-audit/two-minute-mysteries.jpg)
</Zoom>

I've unfortunately lost the book, but I've tried to recreate the style here:

"Dr Haledjian visits a bar on his way back to the office. Inside, a bronzed adventurer, recently shaved, is seated at the bar. "Where are you from", asks Dr Haledjian. "I just got back yesterday from San Jose. I was out there three months digging out a gold seam I found last year. My beard was past my navel, and I just shaved yesterday. I ran out of funding to get the gold back. If you can front me the $2500, I'll give you half the gold". He scratched his bronzed chin and sank into his beer. 

"I wouldn't give you $2500 if my life depended on it." Responded Dr Haledjian. 

*How did Dr Haledjian know the man was lying?*

Now, I've probably made the clues way-y-y too obvious here. The man scratched his "bronzed chin", after only shaving yesterday, and having visited the gold mine for three months. He wouldn't have a bronzed chin if he only shaved yesterday - his skin would be pasty from the beard. 

Weirdly, I'm fairly certain this childhood interest in detective novels has translated to an adulthood interest audit logs. Reading audit and event logs is exactly like a great detective novel - why did they access that file? Is that normal? Is this a legitimate system administrator, or a threat actor trying to evade detection?

Audit and event logging is essential to threat hunting. Many threat actors now attempt to ["live off the land"](/blog/living-off-the-land), abusing administrative tools  to perform their objectives. Strategies like malware signature detection and [application allow-listing](/blog/hands-on-app-control) have no impact here on risk mitigation, as the threat actors are using allow-listed administrative tools. 

Really the only way to identify these users is through comprehensive audit, and identifying a "normal" administrative action from a malicious threat actor "living off the land". One of my favourite security controls available in Red Hat Enterprise Linux is `tlog`, a system for terminal session recording. It allows administrators to 'replay' a user's session - seeing the commands they type, the typos they made, and the sequence of actions as they took place. If you want to try it out, there's a hands-on lab here, and I've included a video below.

One of the difficult things about audit and other event logging is that it's expensive to keep logs "indexed". If I want to search for something, or a user action, I need to be able to keep the data tokenized, and indexed for search. Platforms like Splunk and ElasticSearch excel at this - creating alerts from indexed data, and making it accessible to security teams.

Kubernetes in particular can be difficult to audit. Users interact with the API via command-line tools - but systems and services interact with the API to support things like monitoring and workload scheduling. All of these API interactions create a tremendous volume of audit and event data, which needs to be indexed and searched for anomalous user interactions. This can be incredibly expensive, particularly as platforms scale and grow with demand.

How do we keep all this data indexed, and readily searchable for threat hunting?

## RHACS and Audit

I'd argue there's a better way. We don't need to keep Kubernetes event and audit data immediately searchable if we can create immediate alerts, and then search the data later for more detail. This is exactly the approach that Red Hat Advanced Cluster Security for Kubernetes takes with OpenShift. I've covered RHACS in a few articles before, looking at [the new RHACS scanner](https://www.stb.id.au/blog/rhacs-scanner-v4), ["living off the land"](https://www.stb.id.au/blog/living-off-the-land-containers), [Sigstore support](https://www.stb.id.au/blog/sigstore-and-stackrox) and [CVE data](https://www.stb.id.au/blog/rhsa-cves-rhacs-oh-my), and I think it's worth revisiting how RHACS integrates with OpenShift, and particularly audit logs.

RHACS uses a hub-and-spoke model to secure Kubernetes platforms, including OpenShift. It comprises 'Central', supporting the vulnerability scanner, API, UI, etc, and 'Secured Cluster Services', comprising an eBPF probe, admission controller, and audit integations. 

![acs-image1](/static/images/ocp-audit/acs-image1.png)

RHACS integrates with OpenShift audit through a simple Go-based file reader, included with the [RHACS Secured Cluster Services](). You can see the code [here](https://github.com/stackrox/stackrox/blob/2c3323ce02da5d47f2702f91f802ba1973a1b545/compliance/collection/auditlog/auditlog.go):

```go
// Reader provides functionality to read, parse and send audit log events to Sensor.
type Reader interface {
	// StartReader will start the audit log reader process which will continuously read and send events until stopped.
	// Returns true if the reader can be started (log exists and can be read). Log file missing is not considered an error.
	StartReader(ctx context.Context) (bool, error)
	// StopReader will stop the reader if it's started.
	StopReader()
}
```

Each audit event is captured and sent to the Sensor, to be relayed to RHACS Central. You can see data collected for each audit event in the [StackRox source](https://github.com/stackrox/stackrox/blob/2c3323ce02da5d47f2702f91f802ba1973a1b545/compliance/collection/auditlog/auditevent.go#L29):

```go
type auditEvent struct {
	Annotations              map[string]string `json:"annotations"`
	APIVersion               string            `json:"apiVersion"`
	AuditID                  string            `json:"auditID"`
	Kind                     string            `json:"kind"`
	Level                    string            `json:"level"`
	ObjectRef                objectRef         `json:"objectRef"`
	RequestReceivedTimestamp string            `json:"requestReceivedTimestamp"`
	RequestURI               string            `json:"requestURI"`
	ResponseStatus           responseStatusRef `json:"responseStatus"`
	SourceIPs                []string          `json:"sourceIPs"`
	Stage                    string            `json:"stage"`
	StageTimestamp           string            `json:"stageTimestamp"`
	User                     userRef           `json:"user"`
	ImpersonatedUser         *userRef          `json:"impersonatedUser,omitempty"`
	UserAgent                string            `json:"userAgent"`
	Verb                     string            `json:"verb"`
}
```
#### Diagram-2

You can see some interesting information captured here, which we can use to generate Red Hat Advanced Cluster Security for Kubernetes (RHACS) alerts. I can capture the fact that a user action is impersonated - this could potentially represent a user evading threat detection, and trying to disguise their actions as another platform user. I can also capture the source IP, which can be really useful if users are supposed to administer OpenShift via a 'bastion host', and this can capture attempts to access the API from other locations within the organisation (or externally).

Currently Red Hat Advanced Cluster Security for Kubernetes (RHACS) supports a limited number of high-interest audit events, which are also shown in the [StackRox source](https://github.com/stackrox/stackrox/blob/2c3323ce02da5d47f2702f91f802ba1973a1b545/compliance/collection/auditlog/auditevent.go#L14):
```go
// The audit logs report the resource all as one word, but the k8s event object (and elsewhere) uses underscore
	auditResourceToKubeResource = map[string]storage.KubernetesEvent_Object_Resource{
		"pods_exec":                  storage.KubernetesEvent_Object_PODS_EXEC,
		"pods_portforward":           storage.KubernetesEvent_Object_PODS_PORTFORWARD,
		"secrets":                    storage.KubernetesEvent_Object_SECRETS,
		"configmaps":                 storage.KubernetesEvent_Object_CONFIGMAPS,
		"clusterroles":               storage.KubernetesEvent_Object_CLUSTER_ROLES,
		"clusterrolebindings":        storage.KubernetesEvent_Object_CLUSTER_ROLE_BINDINGS,
		"networkpolicies":            storage.KubernetesEvent_Object_NETWORK_POLICIES,
		"securitycontextconstraints": storage.KubernetesEvent_Object_SECURITY_CONTEXT_CONSTRAINTS,
		"egressfirewalls":            storage.KubernetesEvent_Object_EGRESS_FIREWALLS,
	}
```
Though this is only a subset of audit events, these are a lot of the high-interest events I want to investigate on a cluster.

- `pods_exec`: Records user attempts to exec into a container, which could represent a user trying to access sensitive data inside the pod or make changes.

- `pods_portforward`: Records attempts to forward ports inside a pod. Potentially represents efforts to exfiltrate data, or redirect pod traffic to create alternate C2 channels.

- `secrets`: Records user attempts to access secrets. This can be a really useful event to alert on, particularly when secrets are managed externally (and users shouldn't be creating / accessing secrets within the cluster)

- `configmaps`: Records user attempts to access config maps. Similar to secrets, this records user attempts to access or update config maps, potentially representing attempts to weaken an application configuration.

- `clusterroles`: Records attempts to create Kubernetes cluster roles.

- `clusterrolebindings`: Records attempts to create Kubernetes cluster role bindings. This could represent user attempts to increase their privileges on a cluster, or grant additional privileges to service accounts.

- `networkpolicies`: Records attempts by users to make changes to network policies, which could represent attempts to exfiltrate data, or expose ports for alternate C2.

- `securitycontextconstraints`: (OpenShift-specific) Records attempts to modify OpenShift security context constraints (SCCs), which control the privileges for a workload.

- `egressfirewalls`: (OpenShift-specific) Records attemspts to modify OpenShift egress firewalls, which may represent attempts to exfiltrate data or communicate with C2.

These events are exposed to Red Hat Advanced Cluster Security for Kubernetes (RHACS) users via `Runtime` policies. Let's look at an example for a secret located inside the cluster.

Create RHACS policy for audit and flagging activity.
- Create egress firewall and explain what it is
- Create policy to alert on changes
- Pretend you're a malicious actor, and want to exfiltrate data - but all your activity is captured
- Show alerts

Show how to get more data from `oc adm logs`.

## OpenShift and audit
What do you do with all of the audit data? S3 Glacier - doesn't need to be immediately retrievable, as there's 5 days on the nodes. But it's being kept - which meets compliance obligations - can be retrieved if needed.

Show how to configure S3 Glacier storage with OpenShift. 

